TABLE E.1: ${\epsilon }^{ - },{\epsilon }^{ + },{\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ and $\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ for each model

<table><tr><td>Model</td><td>${\epsilon }^{ - }$</td><td>${\epsilon }^{ + }$</td><td>${\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td><td>$\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td></tr><tr><td>VG</td><td>0.02/G</td><td>0.02/M</td><td>${\sigma }_{CGMY}^{2}\left( {C, G, M,0,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td><td>${\omega }_{CGMY}\left( {C, G, M,0,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td></tr><tr><td>CGMY</td><td>0.01/G</td><td>0.01/M</td><td>${\sigma }_{CGMY}^{2}\left( {C, G, M, Y,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td><td>${\omega }_{CGMY}\left( {C, G, M, Y,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td></tr><tr><td>NIG</td><td>0.05/α</td><td>0.05/α</td><td>-</td><td>-</td></tr><tr><td>Merton's</td><td>0</td><td>0</td><td>0</td><td>$- \lambda \left( {\exp \left( {\alpha  + {\delta }^{2}/2}\right)  - 1}\right)$</td></tr><tr><td>Kou's</td><td>0</td><td>0</td><td>0</td><td>$- \lambda \left( {\frac{p{\eta }_{1}}{{\eta }_{1} - 1} + \frac{\left( {1 - p}\right) {\eta }_{2}}{{\eta }_{2} + 1} - 1}\right)$</td></tr></table>

<table><tr><td>Model</td><td>${\epsilon }^{ - }$</td><td>${\epsilon }^{ + }$</td><td>${\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td><td>$\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td></tr><tr><td>VG</td><td>0.02/G</td><td>0.02/M</td><td>${\sigma }_{CGMY}^{2}\left( {C, G, M,0,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td><td>${\omega }_{CGMY}\left( {C, G, M,0,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td></tr><tr><td>CGMY</td><td>0.01/G</td><td>0.01/M</td><td>${\sigma }_{CGMY}^{2}\left( {C, G, M, Y,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td><td>${\omega }_{CGMY}\left( {C, G, M, Y,{\epsilon }^{ - },{\epsilon }^{ + }}\right)$</td></tr><tr><td>NIG</td><td>0.05/α</td><td>0.05/α</td><td>-</td><td>-</td></tr><tr><td>Merton's</td><td>0</td><td>0</td><td>0</td><td>$- \lambda \left( {\exp \left( {\alpha  + {\delta }^{2}/2}\right)  - 1}\right)$</td></tr><tr><td>Kou's</td><td>0</td><td>0</td><td>0</td><td>$- \lambda \left( {\frac{p{\eta }_{1}}{{\eta }_{1} - 1} + \frac{\left( {1 - p}\right) {\eta }_{2}}{{\eta }_{2} + 1} - 1}\right)$</td></tr></table>

In Equation (E.1), the function $w\left( {x,\tau }\right)$ as well as its derivatives $\frac{\partial w}{\partial x}\left( {x,\tau }\right) ,\frac{{\partial }^{2}w}{\partial {x}^{2}}\left( {x,\tau }\right)$ and $\frac{\partial w}{\partial \tau }\left( {x,\tau }\right)$ can be calculated by the neural network itself or the back-propagation of the neural network. Then the terms remaining to be calculated are ${\int }_{y <  - {\epsilon }^{ - }\text{or }y > {\epsilon }^{ + }}(w\left( {x + y,\tau }\right)$ $- w\left( {x,\tau }\right) )m\left( {dy}\right) ,{\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ and $\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ .

In Equation (E.1), the function $w\left( {x,\tau }\right)$ as well as its derivatives $\frac{\partial w}{\partial x}\left( {x,\tau }\right) ,\frac{{\partial }^{2}w}{\partial {x}^{2}}\left( {x,\tau }\right)$ and $\frac{\partial w}{\partial \tau }\left( {x,\tau }\right)$ can be calculated by the neural network itself or the back-propagation of the neural network. Then the terms remaining to be calculated are ${\int }_{y <  - {\epsilon }^{ - }\text{or }y > {\epsilon }^{ + }}(w\left( {x + y,\tau }\right)$ $- w\left( {x,\tau }\right) )m\left( {dy}\right) ,{\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ and $\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ .

### E.2 Pre-calculations

### E.2 Pre-calculations

In Table E.1, we list the choice of ${\epsilon }^{ - },{\epsilon }^{ + }$ and the expressions of ${\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ , and $\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ for each model. ${\sigma }^{2}\left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ and $\omega \left( {{\epsilon }^{ - },{\epsilon }^{ + }}\right)$ are calculated before training.